{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "506f7561",
   "metadata": {},
   "source": [
    "## Gradio\n",
    "Gradio creates interfaces for the ML models. Say we have created an image classification problem or object detection problem or ML model and we need to quickly test it by using some web interface. We dont need to wait for UI people to make interfaces.\n",
    "We can generate ease to use UI  for our ML model, fucntions or API \n",
    "Eg: We can use gradio for comparing transfer learning models which we are doing here\n",
    "\n",
    "Refer: https://www.youtube.com/watch?v=zoEJQr1VJ3Q      \n",
    "https://www.youtube.com/watch?v=wruyZWre2sM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd7d35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "def greet(name):\n",
    "    return \"Hello \" +name + \"!\"\n",
    "\n",
    "iface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")  # not only text we can input image as well. \n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e190779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97f0429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download human-readable labels for ImageNet.\n",
    "response = requests.get(\"https://git.io/JJkYN\")  # all the labels are gonna read from this url.\n",
    "# 1000 class labels are there. wrt imagenet\n",
    "labels = response.text.split(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab30c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the weights of state of the art models of mobilenet and inception v3\n",
    "mobile_net = tf.keras.applications.MobileNetV2()\n",
    "inception_net = tf.keras.applications.InceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7c2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_with_mobile_net(im):\n",
    "    im = Image.fromarray(im.astype('uint8'), 'RGB')\n",
    "    im = im.resize((224, 224))\n",
    "    arr = np.array(im).reshape((-1, 224, 224, 3))\n",
    "    arr = tf.keras.applications.mobilenet.preprocess_input(arr)\n",
    "    prediction = mobile_net.predict(arr).flatten()\n",
    "    return {labels[i]: float(prediction[i]) for i in range(1000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image_with_inception_net(im):\n",
    "    # Resize the image to\n",
    "    im = Image.fromarray(im.astype('uint8'), 'RGB')\n",
    "    im = im.resize((299, 299))\n",
    "    arr = np.array(im).reshape((-1, 299, 299, 3))\n",
    "    arr = tf.keras.applications.inception_v3.preprocess_input(arr)\n",
    "    prediction = inception_net.predict(arr).flatten()\n",
    "    return {labels[i]: float(prediction[i]) for i in range(1000)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagein = gr.inputs.Image()  # consider one input\n",
    "label = gr.outputs.Label(num_top_classes=3)  # how many # of labels we are focussing on\n",
    "sample_images = [\n",
    "                 [\"monkey.jpg\"],\n",
    "                 [\"sailboat.jpg\"],\n",
    "                 [\"bicycle.jpg\"],\n",
    "                 [\"download.jpg\"],\n",
    "                 [\"fox.jpg\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ca2e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(\n",
    "    [classify_image_with_mobile_net, classify_image_with_inception_net],\n",
    "    imagein,\n",
    "    label,\n",
    "    title=\"MobileNet vs. InceptionNet\",\n",
    "    description=\"\"\"Let's compare 2 state-of-the-art machine learning models that classify images into one of 1,000 categories: MobileNet (top),\n",
    "          a lightweight model that has an accuracy of 0.704, vs. InceptionNet\n",
    "          (bottom), a much heavier model that has an accuracy of 0.779.\"\"\",\n",
    "    examples=sample_images).launch();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ced859",
   "metadata": {},
   "source": [
    "#### Output will be as follows\n",
    "\n",
    "Running locally at: http://127.0.0.1:7861/\n",
    "To create a public link, set `share=True` in `launch()`.\n",
    "Interface loading below...\n",
    "Tip: Add interpretation to your model by simply adding `interpretation=\"default\"` to `Interface()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2e22d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
